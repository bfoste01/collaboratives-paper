#Articles

The following document reflects some of my initial thoughts about articles I am encountering as I am immersing myself, once again, in the collaborative literature. Each article/chapter/commentary is introduced with it's BibDesk key. 

**barile2012multilevel**:

* There is no meta-theoretical or even midlevel-theoretical references in this work. Instead, the author is staying really close to the results from previous coalition studies (i.e., this is related to this, etc.). This is not a bad thing, but has me thinking that something I can add to my work is some kind of nod to the importance of scientific paradigms, and what these theoretical orientations open up. 
* Heavy use of the coalition's *Theory of Change* as a way of justifying dimensional selection/understanding of the data at hand. This fits well with how I think about this, and have written about it. 
* A major point of this article is to examine the factor structure of the dimensions of collaboration, and to do so in a multilevel SEM framework.  However, one could also argue that if the Theory of Change drives you to select dimensions of coalition functioning, then your indicators will always be so specific that your results simply cannot generalize.
* A critical thing this study ignores is that a multilevel model will allow you to see variation in the nested levels, but the factor structure has to be the same at level 1. The study doesn't violate this explicitly, but it's making the multilevel model sound like it's doing more than it is in the context of this study. 
* Most of these studies examined measurement structure at the individual level without accounting for nesting of observations (Jasuja et al. 2005; Kumpfer et al. 1993; Valente et al. 2007), another surveyed only collaborative directors (Thomson et al. 2007), and others have aggregated data to the setting level and then examined measurement structure.
* "MCFA accounts for the nested structure of the data (i.e., the non- independence of observations within collaboratives) ..." Nice.
* "MCFA is superior to single level latent factor modeling of collaboration because it accounts for the unreliability of individual level reports of collaborative level constructs (Mehta and Neale 2005), providing more accurate and precise estimates of associations at the collaborative level..." Nice. 
* Article pushes really hard for reliable ad valid measures of collaboration. SEM will buy you some cach√® on the reliable front, but you still have to grapple with construct validity and content validity (at least as it pertains to . If you presuppose measures onto the collaborative, keeping in mind it is the collaborative's theory of change that is driving your dimensional selection, then you are biting off your own hand on the theoretical front. 
